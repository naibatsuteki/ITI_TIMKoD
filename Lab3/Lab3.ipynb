{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from collections import Counter, OrderedDict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    with open(path, 'r') as file:\n",
    "        return file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(prob_list,log_base=2):\n",
    "    h=0\n",
    "    for prob in prob_list:\n",
    "        if prob == 0 or prob == 1:\n",
    "            continue\n",
    "        h -= prob * log(prob,2)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_probability_of_next_element_after_ngram(ngrams_with_next_element,ngram_size): \n",
    "    temp_name = {}\n",
    "    for ngram_with_next_element in ngrams_with_next_element:\n",
    "        ngram = str(ngram_with_next_element[:-1])\n",
    "        next_element = str(ngram_with_next_element[-1])\n",
    "        if ngram in temp_name:\n",
    "            temp_name[ngram].append(next_element)\n",
    "        else:\n",
    "            temp_name[ngram] = [next_element]\n",
    "\n",
    "    omega = len(ngrams_with_next_element) + ngram_size -1  \n",
    "    result = {}       \n",
    "    for ngram,next_elements in temp_name.items():\n",
    "        counter_dict = Counter(next_elements)\n",
    "        prob_dict = {key:value/omega for key, value in counter_dict.items()}\n",
    "        result[ngram] = prob_dict\n",
    "    return result\n",
    "\n",
    "def compute_probabilty_of_char(text_corpus,ngram_size):\n",
    "    ngrams_with_letter = []\n",
    "\n",
    "    for i,_ in enumerate(text_corpus[:-ngram_size]):\n",
    "        ngram_with_letter = text_corpus[i:i+ngram_size]\n",
    "        ngrams_with_letter.append(ngram_with_letter)\n",
    "    else:\n",
    "        #Last iteration is executed in sepcial way. iterable[:-0] return []\n",
    "        ngram_with_letter = text_corpus[-ngram_size:]\n",
    "        ngrams_with_letter.append(ngram_with_letter)\n",
    "    return _compute_probability_of_next_element_after_ngram(ngrams_with_letter,ngram_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilty_of_word(text_corpus,ngram_size):\n",
    "    ngrams_with_next_word = []\n",
    "    text_corpus = text_corpus.split()\n",
    "    for i,_ in enumerate(text_corpus[:-ngram_size]):\n",
    "        ngram_with_next_word = text_corpus[i:i+ngram_size]\n",
    "        ngrams_with_next_word.append(ngram_with_next_word)\n",
    "    else:\n",
    "        #Last iteration is executed in sepcial way. iterable[:-0] return []\n",
    "        ngram_with_next_word = text_corpus[-ngram_size:]\n",
    "        ngrams_with_next_word.append(ngram_with_next_word)\n",
    "    return _compute_probability_of_next_element_after_ngram(ngrams_with_next_word,ngram_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_order(text,prob_function,order,log_base=2):\n",
    "    h = 0\n",
    "    prob_dict =  prob_function(text,order)\n",
    "    for key,value in prob_dict.items():\n",
    "        cum_prob = sum(value.values())\n",
    "        for k in value.keys():\n",
    "            h -= cum_prob * (value[k]/cum_prob) * log(value[k]/cum_prob,log_base)\n",
    "    return h  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_statistics_for_language(text_corpus,start_order=1,end_order=5):\n",
    "    char_entropy = [compute_entropy_order(text_corpus,compute_probabilty_of_char,i)\n",
    "                    for i in range(start_order,end_order+1)]\n",
    "    word_entropy = [compute_entropy_order(text_corpus,compute_probabilty_of_word,i)\n",
    "                    for i in range(start_order,end_order+1)]\n",
    "\n",
    "    return char_entropy,word_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strefa testowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = read_file(\"lab3/norm_wiki_en.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob_dict =  compute_probabilty_of_char(test_text,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.288221453845133"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy(list(test_prob_dict[''].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.288221453845132"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_order(test_text,compute_probabilty_of_char,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwsza lista to entropia kolejnych rzedów dla pojedyńczych znaków. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druga lista to entropia kolejnych rzedów dla słów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Angielski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.288221453845132,\n",
       "  3.5166044715516596,\n",
       "  3.018318628714029,\n",
       "  2.481565226392995,\n",
       "  2.0211841795425207],\n",
       " [11.54399377363079,\n",
       "  6.389171499464897,\n",
       "  2.1764580263700775,\n",
       "  0.484678057213775,\n",
       "  0.10965290888646144])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_en.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Łaciński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.228247465746813,\n",
       "  3.4501258348186434,\n",
       "  2.8234916445972984,\n",
       "  2.1520309167691716,\n",
       "  1.6427633479948576],\n",
       " [11.969194044361334,\n",
       "  4.400023372765311,\n",
       "  1.1668819429215571,\n",
       "  0.3880341890458278,\n",
       "  0.2064678318752358])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_la.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Esperanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.176788490262166,\n",
       "  3.3400049969313046,\n",
       "  2.8718264902832717,\n",
       "  2.39262461467093,\n",
       "  1.9915096242290702],\n",
       " [11.56052995031191,\n",
       "  6.557676609634665,\n",
       "  2.4847179452059187,\n",
       "  0.6336176581141884,\n",
       "  0.16165807248059008])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_eo.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Estoński"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.169833224728489,\n",
       "  3.506957782603394,\n",
       "  3.1344054450799406,\n",
       "  2.6108648187647634,\n",
       "  2.111441373570926],\n",
       " [13.746243545094805,\n",
       "  5.424178340802329,\n",
       "  0.9047388662911572,\n",
       "  0.11619672771532127,\n",
       "  0.02364722325582635])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_et.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Somalijski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.04011386038252,\n",
       "  3.299565271291083,\n",
       "  2.8443705862755846,\n",
       "  2.374309293922122,\n",
       "  1.9450310652105032],\n",
       " [11.73110473724335,\n",
       "  5.398731838327208,\n",
       "  1.608620151841968,\n",
       "  0.40960509009235724,\n",
       "  0.11661039835065375])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_so.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Haitański"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.146385764101037,\n",
       "  3.1138598527812307,\n",
       "  2.27352391448577,\n",
       "  1.4921515557255713,\n",
       "  1.0521423905850413],\n",
       " [8.166919505034997,\n",
       "  3.193109648790236,\n",
       "  1.3113227039865785,\n",
       "  0.8122242421284019,\n",
       "  0.6205694737101665])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_ht.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Język Navaho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.8749372588209434,\n",
       "  2.947264130515973,\n",
       "  2.3675747761828796,\n",
       "  1.7952574012820592,\n",
       "  1.3415909575617972],\n",
       " [9.154011830801968,\n",
       "  3.8639055133499074,\n",
       "  1.7187812157113613,\n",
       "  0.8992338755635442,\n",
       "  0.5385556537930066])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/norm_wiki_nv.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.273001240566633,\n",
       "  2.9158935760366673,\n",
       "  2.0003586572754375,\n",
       "  1.5392811525798737,\n",
       "  1.4385809174668112],\n",
       " [7.748741386140157,\n",
       "  7.486385697485466,\n",
       "  4.406696389524785,\n",
       "  0.5950072737259781,\n",
       "  0.01206208897985021])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample0.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nie jest to język** - Entropia dla pojdyńczych słów i par słów jest podobna. W przypadku języków zauważalny jest duży spadek wartośći."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.12700613554972,\n",
       "  3.2391495355451823,\n",
       "  2.8612788781571723,\n",
       "  2.326683756681927,\n",
       "  1.8135089866130725],\n",
       " [11.500698483659221,\n",
       "  5.372240059108988,\n",
       "  1.574736219727881,\n",
       "  0.5075098044042741,\n",
       "  0.2934569177422313])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample1.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Język** - Entropia kolejnych rzędów dla znaków i słów wykazuje podobną charakterystykę do języków."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.993311800232584,\n",
       "  3.0504387292006654,\n",
       "  2.46765934010102,\n",
       "  1.9397712700800276,\n",
       "  1.7020313384458878],\n",
       " [8.023869815826421,\n",
       "  7.348616622680935,\n",
       "  3.781929363769915,\n",
       "  0.8595036671136258,\n",
       "  0.08199094379393915])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample2.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nie jest to język** - Entropia dla pojdyńczych słów i par słów jest podobna. W przypadku języków zauważalny jest duży spadek wartośći."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.930297834157987,\n",
       "  3.184466603089769,\n",
       "  2.627894943734949,\n",
       "  2.0239906040647146,\n",
       "  1.534242461186765],\n",
       " [9.061119324694518,\n",
       "  5.950215682736722,\n",
       "  2.630802850325793,\n",
       "  1.2640881316354724,\n",
       "  0.4143259561699921])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample3.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Język** - Entropia kolejnych rzędów dla wyrazów i słów wykazuje podobną charakterystykę jak w językach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.2538095673790135,\n",
       "  4.22910114996374,\n",
       "  4.226828376195623,\n",
       "  4.178534315372819,\n",
       "  3.7661305149811053],\n",
       " [17.129669110962844,\n",
       "  3.4442512402777354,\n",
       "  0.23407576260104365,\n",
       "  0.0032274223495286193,\n",
       "  7.608877603594868e-06])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample4.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nie jest to język** - Entropia kolejnych rzędów dla znaków maleje zbyt wolno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.441688018481797,\n",
       "  3.52309786820294,\n",
       "  3.2506203787744012,\n",
       "  2.8342708632659854,\n",
       "  2.172440153984199],\n",
       " [16.509527607380036, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_entropy_statistics_for_language(read_file(\"lab3/sample5.txt\"),end_order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nie jest to język** - Entropia dla słów rzędów biorących pod uwagę przynajmniej jednego poprzednika jest zerowakazuje. Jest to prawdopodobnie sekwenjca wyrazów w której panuje pełen determinizm. Poprzednikiem A zawsze jest B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
