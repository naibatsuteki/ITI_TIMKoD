{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Common code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_word_length(input_text):\n",
    "    words = input_text.split()\n",
    "    words_length = [len(word) for word in words]\n",
    "    return sum(words_length)/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(generator,character_set,lenght,prob_distribution = None):\n",
    "    generator_output = generator(character_set,lenght,prob_distribution)\n",
    "    return generator_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zad_1_generator(character_set,lenght,prob_distribution):\n",
    "    text = \"\"\n",
    "    for i in range(lenght):\n",
    "        text += character_set[randint(0, len(character_set) - 1)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneare_character_set():\n",
    "    ascii_offset = 97\n",
    "    char_set = [chr(i+ascii_offset) for i in range(26)]\n",
    "    char_set.append(chr(32))\n",
    "    return char_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zad1_set = geneare_character_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.64688427299703"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_word_length(generate(zad_1_generator,zad1_set,10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norm_hamlet.txt', 'r') as file:\n",
    "    hamlet = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norm_romeo_and_juliet.txt', 'r') as file:\n",
    "    romeo_and_juliet = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('norm_wiki_sample.txt', 'r') as file:\n",
    "    wiki_sample = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_frequency(text):\n",
    "    counter_dict = dict(sorted(Counter(text).items(),key=lambda x:x[1]))\n",
    "    character_counter = sum(counter_dict.values())\n",
    "    return {key:value/character_counter for key,value in counter_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': 0.0005044040781069715,\n",
       " 'j': 0.0006998606583734229,\n",
       " 'q': 0.0009142323915688859,\n",
       " 'x': 0.0010970788698826631,\n",
       " 'k': 0.0073453843874327724,\n",
       " 'v': 0.007685857140154978,\n",
       " 'b': 0.011317566502525174,\n",
       " 'p': 0.011683259459152728,\n",
       " 'g': 0.014299855614332642,\n",
       " 'c': 0.016544453761908665,\n",
       " 'f': 0.017162348757589704,\n",
       " 'w': 0.019438472160047415,\n",
       " 'y': 0.02010680756353915,\n",
       " 'm': 0.02446359778818812,\n",
       " 'u': 0.026676670680882454,\n",
       " 'd': 0.03190355794026595,\n",
       " 'l': 0.035465911741896436,\n",
       " 'r': 0.047256357067646894,\n",
       " 'n': 0.05142399576300574,\n",
       " 'h': 0.05147443617081644,\n",
       " 's': 0.0525715150406991,\n",
       " 'i': 0.05293720799732666,\n",
       " 'a': 0.060030390345705946,\n",
       " 'o': 0.06838458288935266,\n",
       " 't': 0.07469593891666614,\n",
       " 'e': 0.09329583929686072,\n",
       " ' ': 0.20062041701607158}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_frequency(hamlet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3': 2.367667137569353e-05,\n",
       " '2': 6.313779033518274e-05,\n",
       " '1': 0.00010259890929467196,\n",
       " 'z': 0.0002367667137569353,\n",
       " 'q': 0.0005129945464733599,\n",
       " 'x': 0.0010180968691548217,\n",
       " 'j': 0.0012469713591198592,\n",
       " 'k': 0.006629467985194188,\n",
       " 'v': 0.008184236072198063,\n",
       " 'p': 0.010938622175570411,\n",
       " 'b': 0.012872217004585382,\n",
       " 'g': 0.014221787272999914,\n",
       " 'f': 0.015760770912419994,\n",
       " 'c': 0.016186950997182478,\n",
       " 'w': 0.020101493997963807,\n",
       " 'y': 0.020148847340715193,\n",
       " 'm': 0.02485261272068631,\n",
       " 'u': 0.026367919688730694,\n",
       " 'd': 0.030487660508101366,\n",
       " 'l': 0.03627266054756249,\n",
       " 'r': 0.04672985707182713,\n",
       " 'n': 0.04917644644731546,\n",
       " 's': 0.05091273568153298,\n",
       " 'i': 0.05186769476035263,\n",
       " 'h': 0.05391967294624606,\n",
       " 'a': 0.0622065079277388,\n",
       " 'o': 0.06563962527721436,\n",
       " 't': 0.07435264034346958,\n",
       " 'e': 0.09489609887377967,\n",
       " ' ': 0.20406923058710252}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_frequency(romeo_and_juliet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 0.0008531884640021667,\n",
       " 'z': 0.0012914149776145777,\n",
       " '6': 0.001527860797459176,\n",
       " '7': 0.001531475610071461,\n",
       " '4': 0.0016072939874265694,\n",
       " 'x': 0.001634080675758631,\n",
       " '5': 0.0016506717387739908,\n",
       " '3': 0.0017645846798124117,\n",
       " '8': 0.0019228022472270448,\n",
       " 'j': 0.002127734316092747,\n",
       " '2': 0.003480693795619051,\n",
       " '9': 0.0035601269855864443,\n",
       " '0': 0.004674786895210568,\n",
       " '1': 0.005869806869830876,\n",
       " 'k': 0.006031361187349157,\n",
       " 'v': 0.008546343890470808,\n",
       " 'y': 0.012442741136502646,\n",
       " 'w': 0.012853532149262843,\n",
       " 'b': 0.013455630167965513,\n",
       " 'g': 0.016282506318275353,\n",
       " 'p': 0.017076930905452165,\n",
       " 'f': 0.017617762484751748,\n",
       " 'u': 0.021310247224449554,\n",
       " 'm': 0.02152852629372985,\n",
       " 'c': 0.027571009981424498,\n",
       " 'd': 0.03160977523187864,\n",
       " 'l': 0.03505543315140939,\n",
       " 'h': 0.03646613694522938,\n",
       " 's': 0.053081113336332086,\n",
       " 'r': 0.05432303318740922,\n",
       " 'o': 0.05811617655523373,\n",
       " 'n': 0.05965627210307295,\n",
       " 'i': 0.06095500939341498,\n",
       " 't': 0.06629621943432631,\n",
       " 'a': 0.07209938398958711,\n",
       " 'e': 0.0935363350304724,\n",
       " ' ': 0.17059199786151394}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_frequency(wiki_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = ' '.join([hamlet,romeo_and_juliet,wiki_sample])\n",
    "unigrams_prob = character_frequency(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 0.0008501702101261367,\n",
       " 'z': 0.0012680765014127814,\n",
       " '6': 0.00148849768918951,\n",
       " '7': 0.0014920193714194538,\n",
       " '4': 0.0015658843987039126,\n",
       " '5': 0.0016081445854632362,\n",
       " 'x': 0.00161934172896357,\n",
       " '3': 0.001719393624111712,\n",
       " '8': 0.0018732640476969418,\n",
       " 'j': 0.002097206917703614,\n",
       " '2': 0.0033917411856131514,\n",
       " '9': 0.0034684054987726936,\n",
       " '0': 0.004554347819216339,\n",
       " '1': 0.00571975373869461,\n",
       " 'k': 0.006057022536869981,\n",
       " 'v': 0.008529875559100916,\n",
       " 'y': 0.012640672016433072,\n",
       " 'w': 0.013030766048057599,\n",
       " 'b': 0.013418331692440113,\n",
       " 'g': 0.016230530402366643,\n",
       " 'p': 0.016929448875693916,\n",
       " 'f': 0.017589990042669243,\n",
       " 'u': 0.021444967890836518,\n",
       " 'm': 0.02160859066521236,\n",
       " 'c': 0.027282833433550778,\n",
       " 'd': 0.03160113824381654,\n",
       " 'l': 0.035075232613883754,\n",
       " 'h': 0.03688077200331255,\n",
       " 's': 0.053048995720072496,\n",
       " 'r': 0.05413493804051614,\n",
       " 'o': 0.05834930807522638,\n",
       " 'n': 0.05941845468041953,\n",
       " 'i': 0.06073619593122895,\n",
       " 't': 0.06650868460382836,\n",
       " 'a': 0.0718133313371114,\n",
       " 'e': 0.09354843166396867,\n",
       " ' ': 0.17140524060629642}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najczęsćiej pojawiające sie znaki to spacja i litery `e`, `a`, `t` , `i` a najżadziej `q`, `z`, `6`, `7`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Długość kodów dla najeczęściej występujących znaków jest krótka, a dla najżadziej długa.\n",
    "\n",
    "` e`, `t` -- długość 1\n",
    "\n",
    "` a`, `i` -- długość 2\n",
    "\n",
    "` q`, `z`-- długość 4\n",
    "\n",
    "` 6`, `7` -- długość 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zad_3_generator(character_set,lenght,prob_distribution):\n",
    "    return \"\".join(random.choices(character_set,prob_distribution,k=lenght))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zad_3_text = generate(zad_3_generator,\n",
    "                      character_set=list(unigrams_prob.keys()),\n",
    "                      prob_distribution=list(unigrams_prob.values()),\n",
    "                      lenght = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.007230657989877"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mean_word_length(zad_3_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngram_probabilty(text_corpus,ngram_size):\n",
    "        ngrams = []\n",
    "        for i,_ in enumerate(text_corpus[:-ngram_size]):\n",
    "            ngram = text_corpus[i:i+ngram_size]\n",
    "            ngrams.append(ngram)\n",
    "        else:\n",
    "            #Last iteration is executed in secial way. iterable[:-0] return []\n",
    "            ngram = text_corpus[-ngram_size:]\n",
    "            ngrams.append(ngram)\n",
    "        counter_dict = Counter(ngrams)\n",
    "        omeaga = sum(counter_dict.values())\n",
    "        prob_dict = {key:value/omeaga for key, value in counter_dict.items()}\n",
    "        return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_prob = compute_ngram_probabilty(full_text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999987"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bigrams_prob.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilty_afer_character(character, bigrams_prob,unigram_prob):\n",
    "    result_dict = {}\n",
    "    first_char_prob = unigram_prob[character]\n",
    "    for second_char in unigram_prob.keys():\n",
    "        result_key = character+second_char\n",
    "        try:\n",
    "            result_dict[result_key] = bigrams_prob[result_key]/first_char_prob\n",
    "        except KeyError:\n",
    "            result_dict[result_key] = '0.0'\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e  0.3100256173169632\n",
      "e0 3.185393041739768e-05\n",
      "e1 0.00023552603096500102\n",
      "e2 4.8263530935451035e-05\n",
      "e3 3.8610824748360824e-05\n",
      "e4 2.8958118561270617e-05\n",
      "e5 8.108273197155773e-05\n",
      "e6 7.722164949672165e-06\n",
      "e7 5.791623712254123e-06\n",
      "e8 6.756894330963143e-06\n",
      "e9 1.9305412374180412e-06\n",
      "ea 0.04852608454373988\n",
      "eb 0.004013595232592108\n",
      "ec 0.02928341475977556\n",
      "ed 0.08516100033560334\n",
      "ee 0.02176202609879487\n",
      "ef 0.009319687823635594\n",
      "eg 0.009869892076299736\n",
      "eh 0.0021708936214765873\n",
      "ei 0.010900801097080968\n",
      "ej 0.0004160316366635879\n",
      "ek 0.00201065869877089\n",
      "el 0.038758511153023305\n",
      "em 0.0222147380189694\n",
      "en 0.08732127598027414\n",
      "eo 0.00531188421475574\n",
      "ep 0.011071653996592467\n",
      "eq 0.002015485051864435\n",
      "er 0.14401644577014847\n",
      "es 0.08164548474226509\n",
      "et 0.02662795528770704\n",
      "eu 0.0032925380804164693\n",
      "ev 0.014680800839945494\n",
      "ew 0.009179723583922786\n",
      "ex 0.010099626483552481\n",
      "ey 0.008835121973043664\n",
      "ez 0.000982645489845783\n"
     ]
    }
   ],
   "source": [
    "e_result = compute_probabilty_afer_character('e',bigrams_prob,unigrams_prob)\n",
    "for key in sorted (e_result.keys(),key=lambda x:x[1]) :  \n",
    "    print(f'{key} {e_result[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1.5804572635958337e-06\n",
      " 0 0.002316423529343627\n",
      " 1 0.023155279368942558\n",
      " 2 0.012809079302356368\n",
      " 3 0.003779400136345504\n",
      " 4 0.0026530609264895397\n",
      " 5 0.0023575154181971186\n",
      " 6 0.0020124489156453616\n",
      " 7 0.0015172389730520005\n",
      " 8 0.001580984082683699\n",
      " 9 0.001419777441796924\n",
      " a 0.11244426611396492\n",
      " b 0.04603187144040439\n",
      " c 0.0531702700809789\n",
      " d 0.03205641467751429\n",
      " e 0.023494024042439932\n",
      " f 0.04174619816062035\n",
      " g 0.018272720062607165\n",
      " h 0.03816382836313646\n",
      " i 0.0618201126846389\n",
      " j 0.00906234194945851\n",
      " k 0.008241557810564407\n",
      " l 0.027154889884015748\n",
      " m 0.038747543912491196\n",
      " n 0.021649630415823597\n",
      " o 0.06086288240198769\n",
      " p 0.040759992828136554\n",
      " q 0.0018022480995871157\n",
      " r 0.0312704005984193\n",
      " s 0.07226904247335882\n",
      " t 0.12977556046655683\n",
      " u 0.01208154214201442\n",
      " v 0.009192466264161234\n",
      " w 0.049136416325194464\n",
      " x 0.0005557941376978682\n",
      " y 0.005658563822760951\n",
      " z 0.0009761957698143601\n"
     ]
    }
   ],
   "source": [
    "space_result = compute_probabilty_afer_character(' ',bigrams_prob,unigrams_prob)\n",
    "for key in sorted (space_result.keys(),key=lambda x:x[1]) :  \n",
    "    print(f'{key} {space_result[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovSource:\n",
    "    \n",
    "    def __init__(self,source_level,text_corpus):\n",
    "        self.text_corpus = text_corpus\n",
    "        self.source_level = source_level\n",
    "        self.prob = self._compute_probabilty(self.text_corpus,self.source_level+1)\n",
    "        self.lower_level_source_instance = None\n",
    "        \n",
    "    def _compute_probabilty(self,text_corpus,ngram_size):\n",
    "        ngrams = []\n",
    "        \n",
    "        for i,_ in enumerate(text_corpus[:-ngram_size]):\n",
    "            ngram = text_corpus[i:i+ngram_size]\n",
    "            ngrams.append(ngram)\n",
    "        else:\n",
    "            #Last iteration is executed in secial way. iterable[:-0] return []\n",
    "            ngram = text_corpus[-ngram_size:]\n",
    "            ngrams.append(ngram)\n",
    "        counter_dict = Counter(ngrams)\n",
    "        omeaga = sum(counter_dict.values())\n",
    "        prob_dict = {key:value/omeaga for key, value in counter_dict.items()}\n",
    "        return prob_dict   \n",
    "    \n",
    "    def generate_next(self,input_state):\n",
    "        # If len of input state is inappropriate then try use lower level source or rise exception.\n",
    "        if len(input_state)==self.source_level:\n",
    "            state_dict = {key[-1]:value for key,value in self.prob.items() if input_state == key[:len(input_state)]}\n",
    "            return random.choices(list(state_dict.keys()),list(state_dict.values()))[0]\n",
    "        else:\n",
    "            if len(input_state)>self.source_level:\n",
    "                raise ValueError('Input state is too long.')\n",
    "            else:\n",
    "                if self.lower_level_source_instance is None:\n",
    "                    self.lower_level_source_instance = MarkovSource(self.source_level - 1,self.text_corpus)\n",
    "                return self.lower_level_source_instance.generate_next(input_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create markov sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1 = MarkovSource(1,full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms3 = MarkovSource(3,full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms5 = MarkovSource(5,full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_zad_5(markov_source,length,input_state=''):\n",
    "    queue = deque(list(input_state),maxlen = markov_source.source_level)\n",
    "    output = []\n",
    "    for i in range(length):\n",
    "        output_char = markov_source.generate_next(\"\".join(queue))\n",
    "        queue.append(output_char)\n",
    "        output.append(output_char)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms1_text = generate_zad_5(ms1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms3_text = generate_zad_5(ms3,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms5_text = generate_zad_5(ms5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bavinon mbr rndat in tho congat f t y romerked juofi ted urermeviciguelle ed d on o tottis vimistran'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ussinocal yorks the mongs the lose also the befor hang was appearca socialso nextrace of films were '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms3_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t mexico citizen kannon angola to the broadcast on the norther with rowspan 2rounded in october 1980'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms5_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
